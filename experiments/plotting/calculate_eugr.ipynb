{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "ENV_NAME = \"MOLavaGridDR-v0\" # CHANGE THIS TO THE NAME OF THE ENVIRONMENT\n",
    "REWARD_DIM = 2 # CHANGE THIS TO THE NUMBER OF OBJECTIVES IN THE ENVIRONMENT\n",
    "SEEDS = [5,26,47,76,92] # CHANGE THIS TO THE SEEDS YOU USE\n",
    "\n",
    "from helpers.utils import ENVIRONMENTS_MAP, get_algorithms\n",
    "ALGORITHMS = get_algorithms(ENV_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate EUM for Generalist and Specialist\n",
    "\n",
    "We don't normalize for EUM unlike in NHGR. The chosen utility functions should already express the weightage and preference over objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 1.]),\n",
       " array([0.01019616, 0.98980384]),\n",
       " array([0.02050503, 0.97949497]),\n",
       " array([0.03075785, 0.96924215]),\n",
       " array([0.04110771, 0.95889229])]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path.append(os.path.abspath(os.path.join('../..')))\n",
    "\n",
    "from mo_utils.performance_indicators import hypervolume, expected_utility\n",
    "from mo_utils.weights import equally_spaced_weights\n",
    "\n",
    "NUM_WEIGHTS = 100 # CHANGE THIS TO THE NUMBER OF WEIGHTS YOU WANT TO USE, NORMALLY ITS 100, FOR MARIO ITS 32\n",
    "EVAL_WEIGHTS = equally_spaced_weights(REWARD_DIM, NUM_WEIGHTS) \n",
    "\n",
    "EVAL_WEIGHTS[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the fronts of all the Specialists for each environment\n",
    "\n",
    "Skip this step if already done before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found front for MOLavaGridCheckerBoard-v0 - GPI-LS, total row: 1\n",
      "Combined front for MOLavaGridCheckerBoard-v0 has 1 rows\n",
      "objective_1, Min: 107.33586502075195, Max: 107.33586502075195\n",
      "objective_2, Min: 218.76215887069705, Max: 218.76215887069705\n",
      "Filtered front for MOLavaGridCheckerBoard-v0 has 1 rows\n",
      "Found front for MOLavaGridSmiley-v0 - GPI-LS, total row: 3\n",
      "Combined front for MOLavaGridSmiley-v0 has 3 rows\n",
      "objective_1, Min: 242.1366844177246, Max: 270.69044494628906\n",
      "objective_2, Min: 192.12224054336548, Max: 225.50174689292908\n",
      "Filtered front for MOLavaGridSmiley-v0 has 3 rows\n",
      "Found front for MOLavaGridSnake-v0 - GPI-LS, total row: 2\n",
      "Combined front for MOLavaGridSnake-v0 has 2 rows\n",
      "objective_1, Min: 222.61119079589844, Max: 234.21388816833496\n",
      "objective_2, Min: 187.73548531532288, Max: 220.5411500930786\n",
      "Filtered front for MOLavaGridSnake-v0 has 2 rows\n",
      "Found front for MOLavaGridIslands-v0 - GPI-LS, total row: 2\n",
      "Combined front for MOLavaGridIslands-v0 has 2 rows\n",
      "objective_1, Min: 87.67960739135742, Max: 124.23237419128418\n",
      "objective_2, Min: 201.163339138031, Max: 204.70165252685547\n",
      "Filtered front for MOLavaGridIslands-v0 has 2 rows\n",
      "Found front for MOLavaGridLabyrinth-v0 - GPI-LS, total row: 3\n",
      "Combined front for MOLavaGridLabyrinth-v0 has 3 rows\n",
      "objective_1, Min: 224.45845794677737, Max: 250.0454330444336\n",
      "objective_2, Min: 170.781818151474, Max: 226.9515025615692\n",
      "Filtered front for MOLavaGridLabyrinth-v0 has 3 rows\n",
      "Found front for MOLavaGridMaze-v0 - GPI-LS, total row: 5\n",
      "Combined front for MOLavaGridMaze-v0 has 5 rows\n",
      "objective_1, Min: 182.38000011444092, Max: 237.33114337921145\n",
      "objective_2, Min: 103.25697684288023, Max: 203.5929992198944\n",
      "Filtered front for MOLavaGridMaze-v0 has 5 rows\n",
      "Found front for MOLavaGridCorridor-v0 - GPI-LS, total row: 6\n",
      "Combined front for MOLavaGridCorridor-v0 has 6 rows\n",
      "objective_1, Min: 187.39089965820312, Max: 265.6644287109375\n",
      "objective_2, Min: 123.38202238082886, Max: 240.20966625213623\n",
      "Filtered front for MOLavaGridCorridor-v0 has 6 rows\n",
      "Found front for MOLavaGridRoom-v0 - GPI-LS, total row: 7\n",
      "Combined front for MOLavaGridRoom-v0 has 7 rows\n",
      "objective_1, Min: 167.6479949951172, Max: 263.860782623291\n",
      "objective_2, Min: 142.7001826763153, Max: 215.7504994869232\n",
      "Filtered front for MOLavaGridRoom-v0 has 7 rows\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from mo_utils.pareto import filter_pareto_dominated\n",
    "\n",
    "curr_envs = ENVIRONMENTS_MAP[ENV_NAME]\n",
    "SPECIALIST_FRONT = \"eval/front\" # don't change this, this is the discounted fronts but poorly named!!\n",
    "path_to_find_fronts = f\"data/single_env/{SPECIALIST_FRONT}/{ENV_NAME}\"\n",
    "\n",
    "for env in curr_envs:\n",
    "    unfiltered_combined_front_df = None\n",
    "    path_to_find_front_for_subenv = path_to_find_fronts + f\"/{env}\"\n",
    "    \n",
    "    for algo in ALGORITHMS:\n",
    "        if os.path.exists(path_to_find_front_for_subenv + f\"/{algo}.csv\"):\n",
    "            front_df = pd.read_csv(path_to_find_front_for_subenv + f\"/{algo}.csv\")\n",
    "            print(f\"Found front for {env} - {algo}, total row: {len(front_df)}\")\n",
    "            if unfiltered_combined_front_df is None:\n",
    "                unfiltered_combined_front_df = front_df\n",
    "            else:\n",
    "                unfiltered_combined_front_df = pd.concat([unfiltered_combined_front_df, front_df])\n",
    "\n",
    "    if unfiltered_combined_front_df is None:\n",
    "        warnings.warn(f\"No fronts found for {env}\")\n",
    "        continue\n",
    "    \n",
    "    unfiltered_combined_front_df = unfiltered_combined_front_df.reset_index(drop=True)\n",
    "    print(f\"Combined front for {env} has {len(unfiltered_combined_front_df)} rows\")\n",
    "\n",
    "    for column in unfiltered_combined_front_df.columns:\n",
    "        min_value = unfiltered_combined_front_df[column].min()\n",
    "        max_value = unfiltered_combined_front_df[column].max()\n",
    "        print(f\"{column}, Min: {min_value}, Max: {max_value}\")\n",
    "\n",
    "    combined_front_array = unfiltered_combined_front_df.to_numpy()\n",
    "    filtered_combined_front_array = filter_pareto_dominated(combined_front_array)\n",
    "\n",
    "    combined_front_df = pd.DataFrame(filtered_combined_front_array, columns=unfiltered_combined_front_df.columns)\n",
    "    print(f\"Filtered front for {env} has {len(combined_front_df)} rows\")\n",
    "    save_dir = f\"data/single_env/combined_fronts/{ENV_NAME}/\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    combined_front_df.to_csv(f\"{save_dir}/{env}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.utils import ENVIRONMENTS_MAP\n",
    "\n",
    "FRONT = \"eval/discounted_front\" # don't change this, front extracted for specialists are only the discounted ones!!\n",
    "file_path = f\"data/{FRONT}/{ENV_NAME}\"\n",
    "scores_save_path = f\"data/eugr_scores/{ENV_NAME}\"\n",
    "\n",
    "os.makedirs(f\"{scores_save_path}\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "specialist_eums = []\n",
    "\n",
    "for env in ENVIRONMENTS_MAP[ENV_NAME]:\n",
    "    best_env_front_path = f\"data/single_env/combined_fronts/{ENV_NAME}/{env}.csv\"\n",
    "    assert os.path.exists(best_env_front_path), f\"File {best_env_front_path} does not exist\"\n",
    "    \n",
    "    best_env_front = pd.read_csv(best_env_front_path)\n",
    "    data_array = best_env_front.to_numpy()\n",
    "    specialist_eums.append(expected_utility(data_array, weights_set=EVAL_WEIGHTS))\n",
    "\n",
    "specialist_data = {f\"eum/{env}\": [specialist_eums[i]] for i, env in enumerate(ENVIRONMENTS_MAP[ENV_NAME])}\n",
    "specialist_eum = pd.DataFrame(specialist_data)\n",
    "specialist_eum.to_csv(f\"{scores_save_path}/specialist.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate EUM for GENERALIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "for algo in ALGORITHMS:\n",
    "    for seed in SEEDS:\n",
    "        generalist_eums = []\n",
    "        for env in ENVIRONMENTS_MAP[ENV_NAME]:\n",
    "            file = f\"{file_path}/{algo}/seed_{seed}/{env}.csv\"\n",
    "            assert os.path.exists(file), f\"File {file} does not exist\"\n",
    "            data = pd.read_csv(file)\n",
    "            # Convert dataframe to numpy array of vectors\n",
    "            data_array = data.to_numpy()\n",
    "\n",
    "            generalist_eums.append(expected_utility(data_array, weights_set=EVAL_WEIGHTS))\n",
    "\n",
    "        data = {f\"eum/{env}\": [generalist_eums[i]] for i, env in enumerate(ENVIRONMENTS_MAP[ENV_NAME])}\n",
    "        df = pd.DataFrame(data)\n",
    "        os.makedirs(f\"{scores_save_path}/{algo}/\", exist_ok=True)\n",
    "        df.to_csv(f\"{scores_save_path}/{algo}/seed_{seed}.csv\", index=False)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate EUGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the normalized hypervolumes of the specialists\n",
    "specialist_eum_data = pd.read_csv(f\"{scores_save_path}/specialist.csv\")\n",
    "\n",
    "for algo in ALGORITHMS:\n",
    "    for seed in SEEDS:\n",
    "        # get the normalized hypervolumes we extracted earlier\n",
    "        file = f\"{scores_save_path}/{algo}/seed_{seed}.csv\"\n",
    "        seed_eum_data = pd.read_csv(file)\n",
    "\n",
    "        for env in ENVIRONMENTS_MAP[ENV_NAME]:\n",
    "            # Filter columns that start with \"eum\"\n",
    "            col = f\"eum/{env}\"\n",
    "\n",
    "            specialist_eum = specialist_eum_data[col].values[0]\n",
    "            generalist_eum = seed_eum_data[col].values[0]\n",
    "            \n",
    "            env_eugr = max(generalist_eum / specialist_eum, 0) # ensure that the EUGR is not negative\n",
    "\n",
    "            seed_eum_data[f'EUGR/{env}'] = env_eugr\n",
    "        \n",
    "        seed_eum_data.to_csv(f\"{scores_save_path}/{algo}/seed_{seed}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
