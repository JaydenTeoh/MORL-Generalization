{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "ENV_NAME = \"MOHalfCheetahDR-v5\" # CHANGE THIS TO THE NAME OF THE ENVIRONMENT\n",
    "REWARD_DIM = 2 # CHANGE THIS TO THE NUMBER OF OBJECTIVES IN THE ENVIRONMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Normalization Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MOHalfCheetahDefault-v5': {0: [0, 836], 1: [-353, -3.4]},\n",
       " 'MOHalfCheetahLight-v5': {0: [0, 1060], 1: [-345, -4.3]},\n",
       " 'MOHalfCheetahHeavy-v5': {0: [0, 227], 1: [-379, -4.3]},\n",
       " 'MOHalfCheetahSlippery-v5': {0: [0, 791], 1: [-411, -3.6]},\n",
       " 'MOHalfCheetahHard-v5': {0: [0, 511], 1: [-417, -3.8]}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evaluation import get_eval_params\n",
    "\n",
    "normalization_data = get_eval_params(ENV_NAME)['normalization']\n",
    "normalization_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Front and Calculate Normalized Hypervolume and EUM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('../..')))\n",
    "\n",
    "def get_normalized_vec_returns(all_vec_returns, minmax_range):\n",
    "    minmax_array = np.array([minmax_range[i] for i in range(all_vec_returns.shape[-1])])\n",
    "    min_vals = minmax_array[:, 0].reshape(1, 1, -1) # reshape to (1, 1, n_objectives) for broadcasting\n",
    "    max_vals = minmax_array[:, 1].reshape(1, 1, -1)\n",
    "\n",
    "    clipped_vec_returns = np.clip(all_vec_returns, min_vals, max_vals) # broadcasted clipping\n",
    "    \n",
    "    # Normalize\n",
    "    normalized_vec_returns = (clipped_vec_returns - min_vals) / (max_vals - min_vals)\n",
    "    \n",
    "    return normalized_vec_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 1.]),\n",
       " array([0.00990285, 0.99009715]),\n",
       " array([0.01981506, 0.98018494]),\n",
       " array([0.02981648, 0.97018352]),\n",
       " array([0.03979621, 0.96020379])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mo_utils.performance_indicators import hypervolume, expected_utility\n",
    "from mo_utils.weights import equally_spaced_weights\n",
    "\n",
    "NUM_WEIGHTS = 100\n",
    "EVAL_WEIGHTS = equally_spaced_weights(REWARD_DIM, NUM_WEIGHTS) \n",
    "\n",
    "EVAL_WEIGHTS[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the fronts and calculate normalized hypervolume and EUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.utils import ENVIRONMENTS_MAP, ALGORITHMS\n",
    "\n",
    "FRONT = \"eval/discounted_front\" # change this if you are using undiscounted front, but why?\n",
    "file_path = f\"data/{FRONT}/{ENV_NAME}/\"\n",
    "scores_save_path = f\"data/scores/{ENV_NAME}/\"\n",
    "\n",
    "SEEDS = [5,26,47,76,92]\n",
    "\n",
    "# Load the data\n",
    "for algo in ALGORITHMS:\n",
    "    for seed in SEEDS:\n",
    "        normalized_hypervolumes = []\n",
    "        normalized_eums = []\n",
    "        for env in ENVIRONMENTS_MAP[ENV_NAME]:\n",
    "            min_max_ranges = normalization_data[env]\n",
    "            file = f\"{file_path}/{algo}/seed_{seed}/{env}.csv\"\n",
    "            assert os.path.exists(file), f\"File {file} does not exist\"\n",
    "            data = pd.read_csv(file)\n",
    "            # Convert dataframe to numpy array of vectors\n",
    "            data_array = data.to_numpy()\n",
    "            normalized_front = get_normalized_vec_returns(data_array, min_max_ranges)\n",
    "\n",
    "            normalized_hypervolumes.append(hypervolume(np.zeros(REWARD_DIM), normalized_front[0]))\n",
    "            normalized_eums.append(expected_utility(normalized_front[0], weights_set=EVAL_WEIGHTS))\n",
    "\n",
    "        data = {f\"normalized_hypervolume/{env}\": [normalized_hypervolumes[i]] for i, env in enumerate(ENVIRONMENTS_MAP[ENV_NAME])}\n",
    "        data.update({f\"normalized_eum/{env}\": [normalized_eums[i]] for i, env in enumerate(ENVIRONMENTS_MAP[ENV_NAME])})\n",
    "        df = pd.DataFrame(data)\n",
    "        os.makedirs(f\"{scores_save_path}/{algo}/\", exist_ok=True)\n",
    "        df.to_csv(f\"{scores_save_path}/{algo}/seed_{seed}.csv\", index=False)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
